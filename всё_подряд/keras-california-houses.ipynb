{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991fd986",
   "metadata": {
    "papermill": {
     "duration": 0.008713,
     "end_time": "2023-12-25T11:37:59.857999",
     "exception": false,
     "start_time": "2023-12-25T11:37:59.849286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Контекст\n",
    "\n",
    "Есть данные о домах по округам Калифорнии. Эти данные имеют метрики, такие как население, медианный доход, средняя стоимость дома и т.д., для каждой группы блоков (округов) в Калифорнии.\n",
    "\n",
    "\n",
    "# Задача\n",
    "\n",
    "Построение модели цен на жилье в Калифорнии,модель должна обучаться на таких данных и быть способной прогнозировать среднюю \n",
    "стоимость дома в любом округе, учитывая все остальные метрики. На выходе модели должна быть предсказанная цена дома.\n",
    "\n",
    "# Описание данных\n",
    "\n",
    "Признаки\n",
    "\n",
    "- longitude - географическая долгота округа          \n",
    "- latitude - географическая широта округа\n",
    "- housing_median_age - средний возраст дома\n",
    "- total_rooms - кол-во комнат в округе   \n",
    "- total_bedrooms - кол-во спален в округе   \n",
    "- population - население округа  \n",
    "- households - кол-во домов в округе\n",
    "- median_income - медианный доход в округе (масштабированно до интервала 0.5-15)\n",
    "- ocean_proximity - близость к океану\n",
    "\n",
    "Таргет\n",
    "\n",
    "median_house_value - стоимость дома в округе\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcc82a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T11:37:59.876496Z",
     "iopub.status.busy": "2023-12-25T11:37:59.876189Z",
     "iopub.status.idle": "2023-12-25T11:38:15.239692Z",
     "shell.execute_reply": "2023-12-25T11:38:15.238181Z"
    },
    "papermill": {
     "duration": 15.375868,
     "end_time": "2023-12-25T11:38:15.242343",
     "exception": false,
     "start_time": "2023-12-25T11:37:59.866475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# база\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# для трансформатора\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion \n",
    "\n",
    "# нейросетевое конструирование\n",
    "from keras import models, layers\n",
    "\n",
    "# для итоговой проверки метрики\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# time\n",
    "import time\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b26a5a",
   "metadata": {
    "papermill": {
     "duration": 0.007979,
     "end_time": "2023-12-25T11:38:15.258949",
     "exception": false,
     "start_time": "2023-12-25T11:38:15.250970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Импорт данных / просмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1fba0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T11:38:15.278003Z",
     "iopub.status.busy": "2023-12-25T11:38:15.276406Z",
     "iopub.status.idle": "2023-12-25T11:38:16.143443Z",
     "shell.execute_reply": "2023-12-25T11:38:16.141948Z"
    },
    "papermill": {
     "duration": 0.878031,
     "end_time": "2023-12-25T11:38:16.145138",
     "exception": true,
     "start_time": "2023-12-25T11:38:15.267107",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arenda_california.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marenda_california.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arenda_california.txt'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('arenda_california.txt')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945ad7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f81cda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c62ecf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Рассмотрим расположение домов с помощью широты и долготы --> получим карту Калифорнии\n",
    "plt.figure(figsize = (15,5))\n",
    "sns.scatterplot(data = data,\n",
    "                x = 'longitude',\n",
    "                y = 'latitude',\n",
    "                hue = 'ocean_proximity',\n",
    "                alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca41f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# расположение соответствует действительности, далее рассмотрим распределения числовых признаков\n",
    "data.iloc[:,2:].hist(bins = 50,\n",
    "          figsize = (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dff6a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Распределение признака ocean_proximity\n",
    "plt.figure(figsize = (10,3))\n",
    "sns.countplot(data = data,\n",
    "              x = 'ocean_proximity')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "data['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebf674",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# посмотрим на boxplot графики (без широты/долготы/близости_к_океану)\n",
    "for column_name in data.iloc[:,2:-1].columns:\n",
    "    plt.figure(figsize = (10,1))\n",
    "    sns.boxplot(data = data.iloc[:,2:-1],\n",
    "                x = column_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789256e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# посмотрим на статистические показатели (без широты/долготы)\n",
    "data.iloc[:,2:].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bf18e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c0354",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Вывод по данным\n",
    "\n",
    "- признаки широты и долготы соответствуют дейсвительности\n",
    "\n",
    "---\n",
    "\n",
    "- housing_median_age:\n",
    "    - признак явно ограничен числом 52 (это видно по распределению)\n",
    "    - из-за этого, скорее всего в этом признаке нет выбросов\n",
    "    - будем делать из этого признака категориальный, т.к. будущая модель может воспримать это как числовую границу --> если попадется дом старше 52, вероятность плохого таргетирования вырастет\n",
    "\n",
    "---\n",
    "\n",
    "- median_income:\n",
    "    - распределение, в целом, хорошее\n",
    "    - есть выбросы (в целом, приемлимые)\n",
    "\n",
    "---\n",
    "\n",
    "- median_house_value:\n",
    "    - признак ограничен числом 500 000\n",
    "    - это наш таргет, поэтому надо либо уточнять такие данные, либо их удалять --> удалять\n",
    "\n",
    "---\n",
    "\n",
    "Остальнае признаки имеют распределение с плавным правым хвостом, что нормально, потом сделаем распределение, близкое к нормальному\n",
    "\n",
    "- есть один object признак - \n",
    "- есть пустые значения в признаке total_berooms\n",
    "- дубликатов нет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb095d96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Подготовка данных проектирование признаков / конструирование признаков и создание трансформатора данных для гибкости смены преобразования данных по необходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e704f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Разделение на тренировочный / валидационный / проверочный наборы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5111a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# пока ограничимся обычным разбиение, позже можем обратить внимание на стратификацию по определенномк признаку\n",
    "y = data['median_house_value']\n",
    "X = data.drop('median_house_value', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = RANDOM_STATE)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = RANDOM_STATE,\n",
    "                                                  )\n",
    "\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036072d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### housing_median_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61662642",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Воспользуемся разделение признака с помощью квантиля --> превращаем признак в категориальный\n",
    "# 1 - новый 2 -средний 3 - старый\n",
    "print(np.quantile(X_train['housing_median_age'], q = [0.25, 0.5, 0.75]))\n",
    "\n",
    "def housing_median_age_transformer(x): # записываем эту функция для трансформера\n",
    "        if x <= 18:\n",
    "            return 1\n",
    "        if x > 18 and x <= 29:\n",
    "            return 2\n",
    "        if x > 29 and x <= 37:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "\n",
    "X_train['housing_median_age'] = X_train['housing_median_age'].map(housing_median_age_transformer)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2381e52",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210d64e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vibros_identification_create_filter_frame(df,                           \n",
    "                                              spisok_priznakov):\n",
    "    \n",
    "    '''\n",
    "    df - датафрейм который мы фильтруем по выбросам\n",
    "    spisok_main_priznakov - список названий колонок про которым мы фильтруем выбросы\n",
    "\n",
    "    Например: \n",
    "\n",
    "    spisok_main_priznakov = ['цена на момент снятия с публикации (млн. руб.)',\n",
    "                             'площадь квартиры в квадратных метрах (м²)',\n",
    "                             'всего этажей в доме',\n",
    "                             'высота потолков (м)',\n",
    "                             'площадь кухни (м²)',\n",
    "                             'жилая площадь (м²)']\n",
    "    '''\n",
    "    \n",
    "    data_new = df.copy()\n",
    "\n",
    "    for column_name in spisok_priznakov:\n",
    "        q1 = df[column_name].quantile(0.25)\n",
    "        q3 = df[column_name].quantile(0.75)\n",
    "        IQR = q3-q1     # интерквартильный размах \n",
    "\n",
    "\n",
    "        filter_for_kolonka = (df[column_name] >= (q1 - 1.5*IQR)) & (df[column_name] <= (q3 + 1.5*IQR))   # Получаем маску признаков без выбросов\n",
    "\n",
    "        indexes = data_new[filter_for_kolonka].index\n",
    "        data_new = data_new.loc[indexes] \n",
    "\n",
    "        \n",
    "    return data_new \n",
    "\n",
    "\n",
    "data1 = vibros_identification_create_filter_frame(X_train,\n",
    "                                                  ['median_income'])\n",
    "\n",
    "print('Длина датасета после обработки выбросов: ', len(data1))\n",
    "print('Длина датасета после обработки выбросов: ', len(data))\n",
    "print('Потеряли данных: ', len(X_train) - len(data1)) # Довольно большие потери данных, \n",
    "                                                   # можем оставить признак неизменным\n",
    "                                                   # (позже можем изменить в трансформере)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9f647c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### total_bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3a5ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train['total_bedrooms'] = SimpleImputer(strategy = 'median').fit_transform(np.array(X_train['total_bedrooms']).reshape(-1,1))\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25296685",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce435c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d10d0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()   # можно сразу применять для текста\n",
    "house_sea_1hot_encoded =\\\n",
    "encoder.fit_transform(np.array(X_train['ocean_proximity']).reshape(-1,1))\n",
    "\n",
    "\n",
    "one_hot_data =\\\n",
    "pd.DataFrame(house_sea_1hot_encoded.toarray(),\n",
    "             columns = encoder.categories_)\n",
    "\n",
    "'''X_train = pd.concat([X_train, one_hot_data],axis = 1).drop('ocean_proximity', axis = 1)\n",
    "X_train.head()'''\n",
    "\n",
    "one_hot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd24830",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Конструирование новых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c146b93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train['rooms_per_households'] = X_train['total_rooms'] / X_train['households']\n",
    "X_train['bedrooms_per_rooms'] = X_train['total_bedrooms'] / X_train['total_rooms']\n",
    "X_train['population_per_households'] = X_train['population'] / X_train['households']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fa53d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Построим матрицу корреляции и узнаем признаки, которые взаимосвязанны с таргетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34033e08",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([X_train, y_train], axis = 1).corr().round(2)['median_house_value'].sort_values(ascending = False)\n",
    "# Довавим признак bedrooms_per_rooms, т.к. он даже лучше связан с нащим таргетом, чем total_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7086237",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['rooms_per_households', 'population_per_households'], axis = 1)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ae7f8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Пишем трансформер данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9cb74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# преобразование признака 'housing_median_age'\n",
    "def housing_median_age_transformer(x):\n",
    "    if x <= 18:\n",
    "        return 1\n",
    "    if x > 18 and x <= 29:\n",
    "        return 2\n",
    "    if x > 29 and x <= 37:\n",
    "        return 3\n",
    "    if x > 37:\n",
    "        return 4\n",
    "    \n",
    "################################# Трансформатор входных значений ##########################################################\n",
    "housing_age_ix, rooms_ix, bedrooms_ix = 2, 3, 4\n",
    "\n",
    "class NumpyFeaturesAdderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, features):\n",
    "        return self\n",
    "    def transform(self, features):\n",
    "        # Перевод признака midian_age в категориальный\n",
    "        housing_median_age_cat = [housing_median_age_transformer(i) for i in features[:,2]]\n",
    "        features[:,2] = housing_median_age_cat\n",
    "        bedrooms_per_rooms = features[:,4] / features[:,3]\n",
    "        return np.c_[features, bedrooms_per_rooms]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_attribs = [i for i in X.columns if X[i].dtype != 'object']\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('attrib_changer_adder', NumpyFeaturesAdderTransformer()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('one_hot_encoder', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline),\n",
    "])\n",
    "\n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print('Время трансформации: ', end_time - start_time)\n",
    "\n",
    "X_train = X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858fc1d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape # 8 изначальных признаков (без таргета и без категориального), 1 сконструированный (bedrooms_per_rooms),\n",
    "              # 5 OneHot признаков от категориального ocean_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf741760",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Делаем трансформированные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5d363",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val = full_pipeline.fit_transform(X_val).toarray()\n",
    "X_test = full_pipeline.fit_transform(X_test).toarray()\n",
    "\n",
    "print('Размерность валидационного набора: ', X_val.shape)\n",
    "print('Размерность проверочного набора: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f135492",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac09da0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(((y_pred, y_true)**2)))\n",
    "\n",
    "def builder_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation = 'relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(layers.Dense(16, activation = 'relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss = 'mse',\n",
    "                  metrics = 'mae')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23de76",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Пробуем первую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922e678",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = builder_model()\n",
    "history =\\\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size = 20,\n",
    "          epochs = 500,\n",
    "          verbose = False,\n",
    "          validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543e45d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_history =\\\n",
    "pd.DataFrame(history.history)\n",
    "\n",
    "# LOSS\n",
    "sns.scatterplot(data_history[-50:],\n",
    "                x = data_history[-50:].index,\n",
    "                y = 'loss',\n",
    "                label = 'mse потери на этапе обучения')\n",
    "'''plt.xticks(ticks = np.arange(0,21,2)) # регулировка масштаба \n",
    "'''\n",
    "sns.lineplot(data = data_history[-50:],\n",
    "             x = data_history[-50:].index,\n",
    "             y = 'val_loss',\n",
    "             color = 'green',\n",
    "             label = 'mse потери на этапе проверки')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('эпоха')\n",
    "plt.title('Потери на тренировке и тестировании')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "sns.scatterplot(data_history[-50:],\n",
    "                x = data_history[-50:].index,\n",
    "                y = 'mae',\n",
    "                label = 'MAE на этапе обучения')\n",
    "'''plt.xticks(ticks = np.arange(0,21,2)) # регулировка масштаба '''\n",
    "\n",
    "sns.lineplot(data = data_history[-50:],\n",
    "             x = data_history[-50:].index,\n",
    "             y = 'val_mae',\n",
    "             color = 'green',\n",
    "             label = 'MAE на этапе проверки')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('эпоха')\n",
    "plt.title('MAE на тренировке и тестировании')\n",
    "plt.show()\n",
    "\n",
    "data_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa60ce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Вывод по первой модели: \n",
    "\n",
    "- 500 эпох не достаточно для наилучших показателей модели: видим плавное уменьшение как потерь так и метрики\n",
    "- переобучение не наблюдается --> вводить штрафы / dropout нецелесообразно\n",
    "- увеличим количество эпох "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6d81c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Вторая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f9f8b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss_metric(history):\n",
    "        data_history = pd.DataFrame(history.history)\n",
    "        history_columns = data_history.columns\n",
    "        # LOSS\n",
    "        sns.scatterplot(data_history,\n",
    "                        x = data_history.index,\n",
    "                        y = 'loss',\n",
    "                        label = 'потери на этапе обучения')\n",
    "        '''plt.xticks(ticks = np.arange(0,21,2)) # регулировка масштаба \n",
    "        '''\n",
    "        sns.lineplot(data = data_history,\n",
    "                     x = data_history.index,\n",
    "                     y = 'val_loss',\n",
    "                     color = 'green',\n",
    "                     label = 'потери на этапе проверки')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('эпоха')\n",
    "        plt.title('Потери на тренировке и тестировании')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        # Metric\n",
    "        sns.scatterplot(data_history,\n",
    "                        x = data_history.index,\n",
    "                        y = history_columns[1],\n",
    "                        label = f'{history_columns[1]} на этапе обучения')\n",
    "        '''plt.xticks(ticks = np.arange(0,21,2)) # регулировка масштаба '''\n",
    "\n",
    "        sns.lineplot(data = data_history,\n",
    "                     x = data_history.index,\n",
    "                     y = history_columns[-1],\n",
    "                     color = 'green',\n",
    "                     label = f'{history_columns[1]} на этапе проверки')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.xlabel('эпоха')\n",
    "        plt.title('MAE на тренировке и тестировании')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad34432",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_history = pd.DataFrame(history.history)\n",
    "data_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774127f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = builder_model()\n",
    "history =\\\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size = 16,\n",
    "          epochs = 1000,\n",
    "          verbose = False,\n",
    "          validation_data = (X_val, y_val))\n",
    "plot_loss_metric(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a96f5e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_history = pd.DataFrame(history.history)\n",
    "data_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be66ff0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_to_plot = data_history[-200:]\n",
    "\n",
    "def plot_loss_metric_1(data):\n",
    "        data_history = data\n",
    "        history_columns = data.columns\n",
    "        # LOSS\n",
    "        sns.scatterplot(data_history,\n",
    "                        x = data_history.index,\n",
    "                        y = 'loss',\n",
    "                        label = 'потери на этапе обучения')\n",
    "        '''plt.xticks(ticks = np.arange(0,21,2)) # регулировка масштаба \n",
    "        '''\n",
    "        sns.lineplot(data = data_history,\n",
    "                     x = data_history.index,\n",
    "                     y = 'val_loss',\n",
    "                     color = 'green',\n",
    "                     label = 'потери на этапе проверки')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('эпоха')\n",
    "        plt.title('Потери на тренировке и тестировании')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        # Metric\n",
    "        sns.scatterplot(data_history,\n",
    "                        x = data_history.index,\n",
    "                        y = history_columns[1],\n",
    "                        label = f'{history_columns[1]} на этапе обучения')\n",
    "        '''plt.xticks(ticks = np.arange(0,21,2)) # регулировка масштаба '''\n",
    "\n",
    "        sns.lineplot(data = data_history,\n",
    "                     x = data_history.index,\n",
    "                     y = history_columns[-1],\n",
    "                     color = 'green',\n",
    "                     label = f'{history_columns[1]} на этапе проверки')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.xlabel('эпоха')\n",
    "        plt.title('MAE на тренировке и тестировании')\n",
    "        plt.show()\n",
    "\n",
    "plot_loss_metric_1(data_to_plot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ecf15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Вывод по второй модели:\n",
    "\n",
    "\n",
    "- 1000 эпох не достаточно для наилучших показателей модели: все еще видим уже не плавное, но все же уменьшение как потерь так и метрики\n",
    "- переобучение не наблюдается --> вводить штрафы / dropout нецелесообразно\n",
    "- увеличим количество эпох и добавим callback на 500 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa14b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_mae',\n",
    "    min_delta = 500,\n",
    "    patience = 500,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02259c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = builder_model()\n",
    "history =\\\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size = 16,\n",
    "          epochs = 3000,\n",
    "          verbose = False,\n",
    "          callbacks = callback,\n",
    "          validation_data = (X_val, y_val)) \n",
    "plot_loss_metric(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b12390",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Посмотрим на последние 1000 эпох\n",
    "data_last_100__200 = pd.DataFrame(history.history)[-1000:]\n",
    "plot_loss_metric_1(data_last_100__200)\n",
    "data_history = pd.DataFrame(history.history)\n",
    "data_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3650d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Итог по новой модели\n",
    "\n",
    "- замечаем, что MAE на этапе проверки сшлаживается до 39000 и не уменьшается\n",
    "- в тоже время метрика на обучении уменьшается - что яв. ярким признаком переобучения на тренировочном наборе\n",
    "- останавливаем обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17aee7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Проверка на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aeb061",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mean_absolute_error(y_true = y_test,\n",
    "                    y_pred = y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1247272",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Итог\n",
    "\n",
    "Оптимальная Keras модель показывает mae = 38 823 $"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4202963,
     "sourceId": 7253627,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.594235,
   "end_time": "2023-12-25T11:38:17.678454",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-25T11:37:57.084219",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
